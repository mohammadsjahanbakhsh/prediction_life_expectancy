{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadsjahanbakhsh/project2_quera/blob/main/finall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7dOxUhog1TI"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTyL4-8BCrUk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC7lh54F1XeO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def transform(dataset,country_column) :\n",
        "       \n",
        "        \n",
        "        cols_with_na = dataset.isna().sum()[dataset.isna().sum()>0].index.tolist()\n",
        "        \n",
        "        for col in cols_with_na : \n",
        "          \n",
        "          dataset[col]=dataset.groupby([country_column])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "          \n",
        "        cols_with_na = dataset.isna().sum()[dataset.isna().sum()>0].index.tolist()\n",
        "        \n",
        "        for col in cols_with_na : \n",
        "            dataset.loc[:,col].fillna(dataset[col].median(),inplace=True)\n",
        "            \n",
        "        \n",
        "        return dataset\n",
        "\n",
        "\n",
        "\n",
        "def transform2(dataset,drop_list):\n",
        "  dataset=dataset[dataset.Year>=1950]\n",
        "  dataset.drop(drop_list,axis=1,inplace=True)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "Additional_column=[\"Variant\",\"Notes\",\"ISO3 Alpha-code\",\"ISO2 Alpha-code\",\"SDMX code**\",\"Type\",\"Location code\",\"Parent code\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XK76QZH008K"
      },
      "outputs": [],
      "source": [
        "death=pd.read_csv(\"datasets\\suicide-vs-violent-deaths.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD5xdcYx008P"
      },
      "outputs": [],
      "source": [
        "death=transform2(death,['Population (historical estimates)', 'Continent',\"Code\"])\n",
        "# death=transform(death,'Entity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ8qn_C5008Q"
      },
      "outputs": [],
      "source": [
        "vaccine=pd.read_csv(\"datasets\\child-mortality-vs-share-of-children-immunized-against-diphtheria-pertussis-and-tetanus.csv\")\n",
        "vaccine=transform2(vaccine,['Population (historical estimates)', 'Continent','Code',\"Mortality rate, under-5 (per 1,000 live births)\"])\n",
        "# vaccine=transform(vaccine,'Entity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmiR6ZmvozN6"
      },
      "outputs": [],
      "source": [
        "gdp=pd.read_csv(\"datasets\\life-expectancy-vs-gdp-per-capita.csv\")\n",
        "gdp.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYGXPQ4IpDrZ"
      },
      "outputs": [],
      "source": [
        "gdp=transform2(gdp,['Code', 'Life expectancy at birth (historical)','417485-annotations','Population (historical estimates)','Continent'])\n",
        "# gdp=transform(gdp,'Entity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDpUSqBkARhR"
      },
      "outputs": [],
      "source": [
        "Estimates=pd.read_excel(\"datasets/WPP2022.xlsx\",sheet_name=\"Estimates\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2KVn3L3ARhS"
      },
      "outputs": [],
      "source": [
        "from numpy import nan\n",
        "\n",
        "columns=list(Estimates.iloc[15])\n",
        "Estimates=Estimates[16:]\n",
        "Estimates.columns=columns\n",
        "Estimates=Estimates.set_index(\"Index\")\n",
        "\n",
        "# Estimates=Estimates.loc[Estimates.iloc[:,4].notna(),:]\n",
        "Estimates.replace(\"...\",nan,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJoZks9O-T2I"
      },
      "outputs": [],
      "source": [
        "x=vaccine.merge(death,how=\"outer\").merge(gdp,how=\"outer\")\n",
        "\n",
        "Estimates=Estimates.merge(x,left_on=[\"Region, subregion, country or area *\",\"Year\"],right_on=[\"Entity\",\"Year\"],how=\"left\").drop(\"Entity\",axis=1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcht1HAIxp_Q"
      },
      "outputs": [],
      "source": [
        "hospital_bed=pd.read_csv(\"datasets/hospital_bed.csv\")\n",
        "hospital_bed.drop([\"INDICATOR\",\"SUBJECT\",\"MEASURE\",\"FREQUENCY\",\"Flag Codes\"],axis=1,inplace=True)\n",
        "hospital_bed.rename({\"TIME\":\"Year\",\"Value\":\"hospital_bed\"},axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DczBkMhu_gOp"
      },
      "outputs": [],
      "source": [
        "Estimates=Estimates.merge(hospital_bed,left_on=[\"ISO3 Alpha-code\",\"Year\"],right_on=[\"LOCATION\",\"Year\"],how=\"left\").drop(\"LOCATION\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsZGtI1PD8tj"
      },
      "outputs": [],
      "source": [
        "\n",
        "Estimates.drop(Additional_column,axis=1,inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acXrok3ZgJtA"
      },
      "outputs": [],
      "source": [
        "Medium_variant=pd.read_excel(\"datasets/WPP2022.xlsx\",sheet_name=\"Medium variant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSCCXFOzgJtA"
      },
      "outputs": [],
      "source": [
        "columns=list(Medium_variant.iloc[15])\n",
        "Medium_variant=Medium_variant[16:]\n",
        "Medium_variant.columns=columns\n",
        "Medium_variant=Medium_variant.set_index(\"Index\")\n",
        "Medium_variant=Medium_variant[Medium_variant.iloc[:,4].notna()]\n",
        "# Medium_variant.drop(Additional_column,axis=1,inplace=True)\n",
        "Medium_variant=Medium_variant[Medium_variant.Year==2022]\n",
        "Medium_variant.replace(\"...\",nan,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPbk5HRhC1b_"
      },
      "outputs": [],
      "source": [
        "Estimates.to_csv(\"Estimates3.csv\",index=None)\n",
        "# Medium_variant.to_csv(\"/content/drive/MyDrive/data/Medium_variant.csv\",index=None)\n",
        "# فایلو بدم بچه ها اشتباه داشت"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVf89_Ee1p8W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooR5CSul1qNZ"
      },
      "outputs": [],
      "source": [
        "Estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taN27jgf1RPp"
      },
      "outputs": [],
      "source": [
        "Estimates=pd.read_csv(\"Estimates.csv\")\n",
        "Medium_variant=pd.read_csv(\"Medium_variant.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh3CZJyXgxUE"
      },
      "source": [
        "## model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mJzjjlXPSD_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "Estimates=pd.read_csv(\"/content/drive/MyDrive/project2_quera/Estimates.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omu8jLlHYZnG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def transform(dataset,country_column) :\n",
        "       \n",
        "        \n",
        "        cols_with_na = dataset.isna().sum()[dataset.isna().sum()>0].index.tolist()\n",
        "        \n",
        "        for col in cols_with_na : \n",
        "          \n",
        "          dataset[col]=dataset.groupby([country_column])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "          \n",
        "        cols_with_na = dataset.isna().sum()[dataset.isna().sum()>0].index.tolist()\n",
        "        \n",
        "        for col in cols_with_na : \n",
        "            dataset.loc[:,col].fillna(dataset[col].median(),inplace=True)\n",
        "            \n",
        "        \n",
        "        return dataset\n",
        "\n",
        "\n",
        "Additional_column=[\"Variant\",\"Notes\",\"ISO3 Alpha-code\",\"ISO2 Alpha-code\",\"SDMX code**\",\"Type\",\"Location code\",\"Parent code\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI96Ql1tUWLo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwFB92jQgeLE"
      },
      "outputs": [],
      "source": [
        "\n",
        "Estimates.drop(Additional_column,axis=1,inplace=True)\n",
        "df_est=pd.get_dummies(transform(Estimates,\"Region, subregion, country or area *\"),columns=[\"Region, subregiontry or area *\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNAtcdccoH3B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# df_est=pd.get_dummies(Estimates,columns=[\"Region, subregion, country or area *\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOxNi_uWqWv3"
      },
      "outputs": [],
      "source": [
        "Medium_variant=pd.read_csv(\"/content/drive/MyDrive/project2_quera/Medium_variant.csv\")\n",
        "Medium_variant=Medium_variant.drop(Additional_column,axis=1)\n",
        "df_med=pd.get_dummies(transform(Medium_variant,\"Region, subregion, country or area *\"),columns=[\"Region, subregion, country or area *\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_est.to_csv(\"/content/drive/MyDrive/project2_quera/Estimates_finall.csv\",index=None)\n"
      ],
      "metadata": {
        "id": "gGlBWv2VmirI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRDmHZEw9J3"
      },
      "outputs": [],
      "source": [
        "x_col_est=[\"Life Expectancy\" not in c for c in df_est.columns]\n",
        "y_col_est=[\"Life Expectancy at Birth\" in c for c in df_est.columns]\n",
        "x_Estimates=df_est.loc[:,x_col_est]\n",
        "y_Estimates=df_est.loc[:,y_col_est][\"Life Expectancy at Birth, both sexes (years)\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HhNRgZPX7VT"
      },
      "outputs": [],
      "source": [
        "x_col_med=[\"Life Expectancy\" not in c for c in df_med.columns]\n",
        "y_col_med=[\"Life Expectancy at Birth\" in c for c in df_med.columns]\n",
        "x_Medium=df_med.loc[:,x_col_med]\n",
        "y_Medium=df_med.loc[:,y_col_med][\"Life Expectancy at Birth, both sexes (years)\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PjvkeKkP58N"
      },
      "source": [
        "## predict my feature with decision tree Regressor \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9SNPTTFJOqO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b7Bt855FAiM"
      },
      "outputs": [],
      "source": [
        "df_est.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPBggNaGSCUE"
      },
      "outputs": [],
      "source": [
        "df_est_x.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting and adding my own fits to the \"\"Medium\"\"DataSet those who are forecast more than 0.8 with R2-squares and are foreseeable in my opinion"
      ],
      "metadata": {
        "id": "BH1AaVZR9D0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9ODw8jpcZo8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "my_feature_total=Estimates.columns[-5:].to_list()\n",
        "my_feature=my_feature_total.copy()\n",
        "r2_my_feature=dict()\n",
        "medium_my_feature = dict()\n",
        "my_feature2=[]\n",
        "\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "for i in range(len(my_feature_total)):\n",
        "  j=0\n",
        "  my_feature2.append(my_feature.pop(-1))\n",
        "  x_last=x_Estimates.drop(my_feature_total,axis=1)\n",
        "  y_last=x_Estimates[[my_feature2[-1]]]\n",
        "\n",
        "  r2_scores2 = []\n",
        "  for train_index, test_index in kf.split(x_last):\n",
        "      x_train, x_test = x_last.values[train_index], x_last.values[test_index]\n",
        "      y_train, y_test = y_last.values.ravel()[train_index] , y_last.values.ravel()[test_index]\n",
        "    # x_train,x_test , y_train,y_test = train_test_split(x_last, y_last ,test_size=.2)\n",
        "\n",
        "      std_scaler = StandardScaler().fit(x_train)\n",
        "      x_train = std_scaler.transform(x_train)\n",
        "\n",
        "\n",
        "\n",
        "      regressor = DecisionTreeRegressor( )\n",
        "      regressor.fit(x_train, y_train)\n",
        "      print(j,my_feature2[-1])\n",
        "      j+=1\n",
        "      y_pred = regressor.predict(std_scaler.transform(x_test))\n",
        "      r2_scores2.append(r2_score(y_test, y_pred))\n",
        "\n",
        "  r2_my_feature[my_feature2[-1]]=np.mean(r2_scores2)\n",
        "\n",
        "\n",
        "  if r2_my_feature[my_feature2[-1]] > 0.8:\n",
        "    medium_my_feature[my_feature2[-1]] = regressor.predict(std_scaler.transform(x_Medium.values))\n",
        "\n",
        "print(\"____________________\")\n",
        "for i,j in r2_my_feature.items():\n",
        "    print(i,\" : \", j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjWRhiarl2P3"
      },
      "outputs": [],
      "source": [
        "my_feature_in_medium=list(medium_my_feature.keys())\n",
        "my_feature_in_medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yp7rdWzmPRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_Medium=pd.concat([x_Medium,pd.DataFrame(medium_my_feature)],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36KKKv6-2hoP"
      },
      "outputs": [],
      "source": [
        "pd.concat([x_Medium,y_Medium],axis=1).to_csv(\"Medium_variant_with_my_feature.csv\",index=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F03j10h2_3l"
      },
      "source": [
        "# predicting Life Expectancy at Birth, both sexes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpGHrdHow7cg"
      },
      "source": [
        "## decesion tree in sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHQHP1fI4Pv8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TPQIAGdLgwvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwsuLOpW3Ans"
      },
      "outputs": [],
      "source": [
        "Medium=pd.read_csv(\"/content/drive/MyDrive/project2_quera/Medium_variant_with_my_feature.csv\")\n",
        "x_columns=[\"Life Expectancy\" not in c for c in Medium]\n",
        "y_columns=[\"Life Expectancy at Birth\" in c for c in Medium]\n",
        "x_Medium=Medium.loc[:,x_columns]\n",
        "y_Medium=Medium.loc[:,y_columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Medium.columns.shape"
      ],
      "metadata": {
        "id": "YJyCCUS4Z5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Estimates=pd.read_csv(\"/content/drive/MyDrive/project2_quera/Estimates_finall.csv\")\n",
        "\n",
        "x_Estimates=Estimates.loc[:,x_Medium.columns]\n",
        "y_Estimates=Estimates.loc[:,y_Medium.columns]"
      ],
      "metadata": {
        "id": "4GhQavOJDiz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict on **Medium** dataset **before** feature selection "
      ],
      "metadata": {
        "id": "hc9nGpziQGIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time"
      ],
      "metadata": {
        "id": "O6o0KlQ6pjgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1=time()\n",
        "std_scaler = StandardScaler().fit(x_Estimates)\n",
        "x_train = std_scaler.transform(x_Estimates)\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=313)\n",
        "dt.fit(x_train, y_Estimates)\n",
        "\n",
        "\n",
        "y_pred = dt.predict(std_scaler.transform(x_Medium))\n",
        "\n",
        "t1= time() - t1\n",
        "before = r2_score(y_Medium, y_pred)\n",
        "print(\"r2_score before feature selection :\",before)\n",
        "print(\"runTime :\",t1)"
      ],
      "metadata": {
        "id": "5qVC5zvaQGIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## time run\n"
      ],
      "metadata": {
        "id": "ii5cLWeup0EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **feature selection** with DecisionTree on **Estimates** dataset"
      ],
      "metadata": {
        "id": "r4iPj_UUJZIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test , y_train,y_test = train_test_split(x_Estimates, y_Estimates ,test_size=.2)\n",
        "\n",
        "std_scaler = StandardScaler().fit(x_train)\n",
        "x_train = std_scaler.transform(x_train)\n",
        "\n",
        "\n",
        "  \n",
        "dt = DecisionTreeRegressor(random_state = 313)\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = dt.predict(std_scaler.transform(x_test))\n",
        "\n",
        "\n",
        "r2_score(y_test, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "2Ddn1Ts5H2gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ft_imp = pd.Series(dt.feature_importances_, index=x_Medium.columns).sort_values(ascending=False)\n",
        "ft_imp = ft_imp[ft_imp >= 0.00005].sort_values(ascending=False)\n",
        "ft_imp"
      ],
      "metadata": {
        "id": "qAPlOxdaJYmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "col_import=ft_imp.index.tolist() \n",
        "x_train,x_test , y_train,y_test = train_test_split(x_Estimates.loc[:,col_import], y_Estimates ,test_size=.2)\n",
        "\n",
        "std_scaler = StandardScaler().fit(x_train)\n",
        "x_train = std_scaler.transform(x_train)\n",
        "\n",
        "\n",
        "  \n",
        "dt = DecisionTreeRegressor(random_state = 313)\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = dt.predict(std_scaler.transform(x_test))\n",
        "\n",
        "\n",
        "r2_score(y_test, y_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IYW9YocCJ1vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result predict on **Medium** dataset **after** feature selection "
      ],
      "metadata": {
        "id": "QUwKfu-iLFk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2=time()\n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import])\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import])\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=313)\n",
        "dt.fit(x_train, y_Estimates)\n",
        "\n",
        "\n",
        "y_pred = dt.predict(std_scaler.transform(x_Medium.loc[:,col_import]))\n",
        "\n",
        "\n",
        "t2=time()-t2\n",
        "print(\"r2_score before feature selection :\",before)\n",
        "print(\"runTime before :\",t1)\n",
        "print(\"r2_score after feature selection :\",r2_score(y_Medium, y_pred))\n",
        "print(\"runTime after:\",t2)"
      ],
      "metadata": {
        "id": "vW8SluLCKb6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsTeBtet1ioo"
      },
      "source": [
        "## RandomForestRegressor in sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict on **Medium** dataset **before** feature selection "
      ],
      "metadata": {
        "id": "9pP056c4aMLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "KC7v4gZUq_7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ENzmpfQw5p6"
      },
      "outputs": [],
      "source": [
        "t3=time()\n",
        "\n",
        "std_scaler = StandardScaler().fit(x_Estimates)\n",
        "x_train = std_scaler.transform(x_Estimates)\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 20)\n",
        "\n",
        "rf.fit(x_train, y_Estimates.values.ravel());\n",
        "\n",
        "predictions = rf.predict(std_scaler.transform(x_Medium))\n",
        "\n",
        "t3=time()-t3\n",
        "before=r2_score(y_Medium, predictions)\n",
        "print(\"r2_score before feature selection :\",r2_score(y_Medium, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## run time\n",
        "\n",
        "t3"
      ],
      "metadata": {
        "id": "8DXnjU2UrWPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **feature selection** with *RandomFarest* on **Estimates** dataset"
      ],
      "metadata": {
        "id": "PhMlNzItaYpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test , y_train,y_test = train_test_split(x_Estimates, y_Estimates ,test_size=.2,random_state=313)\n",
        "\n",
        "std_scaler = StandardScaler().fit(x_train)\n",
        "x_train = std_scaler.transform(x_train)\n",
        "\n",
        "\n",
        "  \n",
        "rf = RandomForestRegressor(n_estimators = 20)\n",
        "rf.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "\n",
        "y_pred = rf.predict(std_scaler.transform(x_test))\n",
        "\n",
        "\n",
        "r2_score(y_test, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "o84A-qRKX82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_imp = pd.Series(rf.feature_importances_, index=x_Medium.columns).sort_values(ascending=False)\n",
        "ft_imp = ft_imp[ft_imp >= 0.00005].sort_values(ascending=False)\n",
        "ft_imp"
      ],
      "metadata": {
        "id": "WE0N8ICGYM5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result predict on **Medium** dataset **after** feature selection "
      ],
      "metadata": {
        "id": "5ccEgwCsbu0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t4=time()\n",
        "col_import=ft_imp.index.tolist()\n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import].values)\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import].values)\n",
        "\n",
        "  \n",
        "rf = RandomForestRegressor(n_estimators = 20)\n",
        "rf.fit(x_train, y_Estimates.values.ravel())\n",
        "\n",
        "\n",
        "y_pred = rf.predict(std_scaler.transform(x_Medium.loc[:,col_import].values))\n",
        "\n",
        "\n",
        "t4=time() - t4\n",
        "\n",
        "print(\"r2_score before feature selection :\",before)\n",
        "print(\"runTime before :\",t3)\n",
        "print(\"r2_score after feature selection :\",r2_score(y_Medium, y_pred))\n",
        "print(\"runTime after:\",t4)"
      ],
      "metadata": {
        "id": "tjijXH4mYNWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning a Random Forest"
      ],
      "metadata": {
        "id": "TwGxFbSNeitW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "n_estimators = list(range(10, 26))\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': n_estimators,\n",
        "}\n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import].values)\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import].values)\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "gs = GridSearchCV(rf, param_grid, cv=5)\n",
        "gs.fit(x_train, y_Estimates.values.ravel());\n",
        "\n"
      ],
      "metadata": {
        "id": "bHLyEH2Nejzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs.best_params_"
      ],
      "metadata": {
        "id": "6PdgORhvxTn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_scores=sorted(gs.cv_results_['mean_test_score'].tolist())\n",
        "# min = round(mean_scores[-1],5)\n",
        "mean_scores"
      ],
      "metadata": {
        "id": "FFhewvNk0VLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"darkgrid\", palette=\"rainbow\")\n",
        "plt.figure(figsize=(15,5))\n",
        "scores = gs.cv_results_['mean_test_score']\n",
        "plt.plot(n_estimators, scores)\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlim(15, 25)\n",
        "plt.ylim(0.993, 0.994)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qgYjcN3PyHBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90jrPAu4YZnL"
      },
      "source": [
        "## LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET6AQku39PZO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APp4bwCw9PdE"
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression()\n",
        "std_scaler = StandardScaler().fit(x_Estimates.values)\n",
        "x_train = std_scaler.transform(x_Estimates.values)\n",
        "\n",
        "reg.fit(x_train,y_Estimates.values.ravel())\n",
        "reg_pred = reg.predict(std_scaler.transform(x_Medium.values))\n",
        "\n",
        "\n",
        "r2_score(y_Medium, reg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz0kHNoT9PgL"
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression()\n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import].values)\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import].values)\n",
        "\n",
        "reg.fit(x_train,y_Estimates)\n",
        "reg_pred = reg.predict(std_scaler.transform(x_Medium.loc[:,col_import].values))\n",
        "\n",
        "\n",
        "r2_score(y_Medium, reg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkCoBFxi1uRc"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbSXeXY0YZnM"
      },
      "source": [
        "## AutoML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn8nEraRAm2I"
      },
      "outputs": [],
      "source": [
        "! pip install flaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml import AutoML"
      ],
      "metadata": {
        "id": "khqSxmeTEy0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqEaDF-MC5c7"
      },
      "outputs": [],
      "source": [
        "## without feature selection \n",
        "\n",
        "std_scaler = StandardScaler().fit(x_Estimates.values)\n",
        "x_train = std_scaler.transform(x_Estimates.values)\n",
        "\n",
        "automl = AutoML(task='regression', time_budget=20)\n",
        "automl.fit(x_train, y_Estimates.values.ravel())\n",
        "y_pred = automl.predict(std_scaler.transform(x_Medium.values))\n",
        "r2_score(y_Medium, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI_7XDrMAm7g"
      },
      "outputs": [],
      "source": [
        "## with feature selection \n",
        "\n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import].values)\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import].values)\n",
        "\n",
        "automl = AutoML(task='regression', time_budget=20)\n",
        "automl.fit(x_train, y_Estimates.values.ravel())\n",
        "y_pred = automl.predict(std_scaler.transform(x_Medium.loc[:,col_import].values))\n",
        "r2_score(y_Medium, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDmOiH1eA1vx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQmgt8WjYZnM"
      },
      "source": [
        "## xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMfZyUhXCKFY"
      },
      "outputs": [],
      "source": [
        "\n",
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwTqu-HMBqZT"
      },
      "outputs": [],
      "source": [
        "## without feature selection \n",
        "std_scaler = StandardScaler().fit(x_Estimates.values)\n",
        "x_train = std_scaler.transform(x_Estimates.values)\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 4, alpha = 10, n_estimators = 1000)\n",
        "\n",
        "xg_reg.fit(x_train, y_Estimates.values.ravel())\n",
        "\n",
        "xgb_pred = xg_reg.predict(std_scaler.transform(x_Medium.values))\n",
        "xgb_score = r2_score(y_Medium, xgb_pred)\n",
        "xgb_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## with feature selection \n",
        "std_scaler = StandardScaler().fit(x_Estimates.loc[:,col_import].values)\n",
        "x_train = std_scaler.transform(x_Estimates.loc[:,col_import].values)\n",
        "\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 4, alpha = 10, n_estimators = 1000)\n",
        "\n",
        "xg_reg.fit(x_train, y_Estimates.values.ravel())\n",
        "\n",
        "xgb_pred = xg_reg.predict(std_scaler.transform(x_Medium.loc[:,col_import].values))\n",
        "xgb_score = r2_score(y_Medium, xgb_pred)\n",
        "xgb_score"
      ],
      "metadata": {
        "id": "y5ykGQHiIu5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5TVV94UBt6f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "LbSXeXY0YZnM",
        "wQmgt8WjYZnM"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "d8aa3f3852f3d99752073d03a68f7998bf7e9e0b6712502d1f8ad35f5711b2ca"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}